\documentclass[addpoints]{exam}
\usepackage{url}
\usepackage{amsmath,amsthm,enumitem}
\usepackage{graphicx}
\usepackage{qtree}
\usepackage[nodayofweek,level]{datetime}
\usepackage{color}

\definecolor{qcolor}{rgb}{0, 0, 0.3}
\definecolor{acolor}{rgb}{0, 0, 0}

%\input myfonts

\lhead{Gopal Menon (u0772360)}
\chead{\bf{HW1}}
\rhead{CS 6150 \today}
\headrule

\begin{document}

\section*{Collaborators}

Ben Nelson and I collaborated for this assignment on all questions except question $2$. We discussed $5c$ in some detail and discussed the rest without going into too many specifics.
\qformat{Question \thequestion: \thequestiontitle\dotfill \textbf{[\totalpoints]}}\pointname{}\bonuspointname{}\pointformat{[\bfseries\thepoints]}
\begin{questions}

\color{qcolor}
\titledquestion{Prefix trees revisited}[8]
Recall the prefix tree data structure for storing a collection of strings (Lecture 2). Suppose we wish to support the following operations: ADD string, DELETE string, QUERY string, COUNT-PREFIX. The last operation takes a string $w$ and returns the number of strings in our collection having $w$ as a prefix.

We saw how to build a data structure that supports the first three operations in time $O(|w|)$, where $|w|$ is the length of the string $w$ being added/deleted/queried. Describe a way to modify the procedures so that COUNT-PREFIX can also be answered in time $O(|w|)$.

\color{acolor}
A prefix tree is shown below with the strings $BED, PET, PAT, PATRON$ and $PATENT$. The root of the tree is denoted by $\circ$. Each node of the tree stores a letter that is part of a string along with a count that denotes the number of strings the letter is used in, a marker $\bullet$ when a string ends with the letter and an optional set of pointers to other nodes. A node can have an edge connecting it to another node when the two letters in the nodes are subsequent letters in a string. Although the tree shown does not have directional edges, the edges are to be read as if they were pointing downward. For example, the connected nodes $B, E $ and $D$ after the root show that the string $BED$ has been stored. Each of these letters have a count of $1$ to show that they have been used only in one string and the $\bullet$ after $D$ shows that the string $BED$ end with the node $D$. The letter $P$ has a count of $4$ since it is used in strings $PET, PAT, PATRON$ and $PATENT$. There is a $\bullet$ marker on the letter $T$ in the middle of the string $PATENT$ since $PAT$ is also stored in the tree and the two strings have the first three letters common. 

\Tree[.$\circ$	[.B^1  [.E^1 [.D^1_{\bullet} ]]]
          		[.P^4 [.E^1 [.T^1_{\bullet} ]]
			      [.A^3 [.T^3_{\bullet} [.R^1 [.O^1 [.N^1_{\bullet} ]]]
			      		 [.E^1 [.N^1 [.T^1_{\bullet} ]] ]] ]]]
					 
\textbf{QUERY procedure algorithm:} For the QUERY operation, a client of the prefix tree will start at the root and look for connected nodes starting with the first letter of the string being queried and ending with the last letter of the string. If the last node also has a $\bullet$ marker, then it means that the string being queried, is present in the tree. So the string $BE$ will not be found in the tree even though nodes $B$ and $E$ exist after the root, but the string $BED$ will be found. 

\textbf{QUERY procedure correctness:} Consider the case where the string being queried does not exist in the tree. This could be because the string exists only as a prefix or does not exist at all. In the former case, although the entire query string is found in the tree, since the last letter of the query string will not have a $\bullet$ marker, the procedure will return a result of not found. In the latter case, the in order connected nodes corresponding to the query string will not be found in the tree and the procedure will return a result of not found. In the case the query string exists in the tree, there will be a set of connected nodes starting from the root that match with the string being queried and with the last node marked with a $\bullet$ marker. In this case the string being queried will be searched in the tree by looking for nodes starting after the root in the order of the letters in the query string and with the last node having a $\bullet$ marker. This will be found and the procedure will return a result of found.

\textbf{QUERY procedure running time:} This operation can be carried out in $O(|w|)$ time since the check can be done by navigating the tree starting at the root in order of the letters in the query string once.

\textbf{ADD procedure algorithm:} To ADD a string into the tree, the client will first $QUERY$ the string and if it is not found, start at the root and for a matching prefix of the string being added, that is already in the tree, it will increment the letter count. If the entire string is found, the last letter will be marked with a $\bullet$. If only a prefix of the string is found, the remaining letters will be added to the tree as connected nodes and letter count $1$ after the last letter of the prefix that was found. The last letter of the added string will be marked with a $\bullet$. The tree is shown below after the strings $BE$ and $BELL$ are added to the tree. 

\Tree[.$\circ$	[.B^2  [.E^2_{\bullet} [.D^1_{\bullet} ]]]
          		[.P^4 [.E^1 [.T^1_{\bullet} ]]
			      [.A^3 [.T^3_{\bullet} [.R^1 [.O^1 [.N^1_{\bullet} ]]]
			      		 [.E^1 [.N^1 [.T^1_{\bullet} ]] ]] ]]]

\Tree[.$\circ$	[.B^3  [.E^3_{\bullet} [.D^1_{\bullet} ]
				  [.L^1 [.L^1_{\bullet} ] ]]]
          		[.P^4 [.E^1 [.T^1_{\bullet} ]]
			      [.A^3 [.T^3_{\bullet} [.R^1 [.O^1 [.N^1_{\bullet} ]]]
			      		 [.E^1 [.N^1 [.T^1_{\bullet} ]] ]] ]]]
					 
\textbf{ADD procedure correctness:} Before a string is added to the tree, there is a check to see if it is already present in the tree. This prevents the string from being added to the tree again and keeps the letter usage counts correct and will ensure that the DELETE operation results in the string being removed from the tree if it is not being used as a prefix. For a prefix of a string being added, that is found in the tree, the letter counts are incremented by $1$. This will ensure that the COUNT-PREFIX operation returns the correct result. For a suffix of a string that is not found in the tree, a new branch will be started after the prefix that is found and connected nodes will be appended in order of the suffix with the last node having a $\bullet$ marker. This will ensure that a QUERY operation will find the string in the tree. If a prefix of the string being added is not found in the tree, connected nodes will be appended to the root node in order of the letters in the string being added. Each of these nodes will have a count of $1$ and the last node will be marked with a $\bullet$. This will ensure that a QUERY operation will find the string in the tree. If the string being added is found as a prefix in the tree, the letter usage counts will be incremented and the node corresponding to the last letter of the string will be marked with a $\bullet$. This will ensure that the COUNT-PREFIX and QUERY operations will return the correct result and the DELETE operation will not corrupt the tree after it decrements the letter counts. 

\textbf{ADD procedure running time:} An ADD operation as described above will take two operations (as a QUERY operation is called as part of the ADD) each with $O(|w|)$ checks and so the entire operation will take time $O(|w|)$.

\textbf{DELETE procedure algorithm:} To DELETE a string from the tree, the client will first QUERY the string and if it is found, start at the root and visit every node in order of the letters in the string. The count for each node will be decremented by $1$ and the $\bullet$ marker will be removed from the node corresponding to the last letter. At the point of decrementing the count, if it becomes $0$, the node will be removed. The tree is shown below after the strings $BED$ and $PAT$ are removed from the tree. 

\Tree[.$\circ$	[.B^2  [.E^2_{\bullet} 
				  [.L^1 [.L^1_{\bullet} ] ]]]
          		[.P^4 [.E^1 [.T^1_{\bullet} ]]
			      [.A^3 [.T^3_{\bullet} [.R^1 [.O^1 [.N^1_{\bullet} ]]]
			      		 [.E^1 [.N^1 [.T^1_{\bullet} ]] ]] ]]]

\Tree[.$\circ$	[.B^2  [.E^2_{\bullet} 
				  [.L^1 [.L^1_{\bullet} ] ]]]
          		[.P^3 [.E^1 [.T^1_{\bullet} ]]
			      [.A^2 [.T^2 [.R^1 [.O^1 [.N^1_{\bullet} ]]]
			      		 [.E^1 [.N^1 [.T^1_{\bullet} ]] ]] ]]]
					 
\textbf{DELETE procedure correctness:} Due to the count being decremented by $1$ as described above and and the $\bullet$ marker being removed from the node corresponding to the last letter, the COUNT-PREFIX operation will return the correct result and due to the nodes being removed when the decremented count reaches zero, a QUERY operation will return the correct result. Since a QUERY operation is performed before a string is removed through the DELETE operation, the case where a prefix of the string that exists and has usage counts decremented, but the string to be deleted does not exist in the tree, will not arise.

\textbf{DELETE procedure running time:} A DELETE operation will take two operations each with $O(|w|)$ checks and so the entire operation will take time $O(|w|)$.
					 
\textbf{COUNT-PREFIX procedure algorithm:} The COUNT-PREFIX operation will start at the root of the tree and visit every node in order of the letters in the string prefix. If it does not find a match for the prefix in the tree, it will return zero. If it finds the entire prefix in the tree, it will return the number associated with the last letter of the prefix in the tree. So in the example of the last tree shown above, a $COUNT-PREFIX$ operation with the prefix as $PA$ will return $2$. This means that the tree has two strings with $PA$ as the prefix. These strings are $PATRON$ and $PATENT$. 

\textbf{COUNT-PREFIX procedure correctness:} The ADD and DELETE procedures keep the letter counts updated correctly as described above. As a result of this, the COUNT-PREFIX returns the correct number. 

\textbf{COUNT-PREFIX procedure running time:} As the COUNT-PREFIX operation looks for a match of the prefix in the tree letter by letter, it can be completed in time $O(|w|)$.

\color{qcolor}
\titledquestion{Recurrences, recurrences}
Solve each of the recurrences below, and give the best $O(\cdot)$ bound you can for each of them. [{\em Hint: } You might find chapters 12 and 13 of the Lehman, Leighton book (available from the course homepage) useful.]

\begin{parts}
\part[3] $T(n) = 2T(\sqrt{n}) + 4$.
\part[4] $T(n) = T(n/3) + T(n/2) + \sqrt{n}$.
\part[5] Suppose you have devised a divide-and-conquer algorithm for a certain problem that breaks up a problem of size $n$ into three subproblems of size $n/2$ each, solves them recursively, and then combines the solutions. Suppose the time for breaking up and combination is given by $g(n)$. Suppose in your first attempt, you had a combine step that had $g(n) = n^{1.8}$. Does it make sense to think further and reduce $g(n)$ to $n^{1.5}$? What about reducing it even further to $g(n) = n \log n$? (Assume you only care about the asymptotic running time of the overall procedure.)
\end{parts}


\color{acolor}
\begin{parts}
\part \begin{equation*}
\begin{aligned}
T(n) &= 2T(\sqrt{n}) +4\\
&= 2T(n^{\frac{1}{2}}) +4\\
\text{Let }n &= 2^x \Rightarrow T(n) = T(2^x)\\
\text{Let }T(2^x) &= P(x)\\
P(x)&=2P \left (\frac{x}{2} \right ) + 4\\
&= 2P \left (\frac{x}{2} \right ) + O(1)\\
&= \Theta(\log(x))  \text{, using the Master Theorem \cite{CLRS} case 2, since $a=2$, $b=2$, $f(n) = \Theta(1) = \Theta (n^{log_b a})$}\\
T(n) &= O(\log(x))\\
&= O(\log(\log n))\\
\end{aligned}
\end{equation*}

\part \begin{equation*}
\begin{aligned}
T(n) &= T \left (\frac{n}{3} \right ) + T \left (\frac{n}{2} \right ) + \sqrt{n}\\
2T\left (\frac{n}{3} \right) + \sqrt{n} &\leq T(n) \leq 2T \left (\frac{n}{2} \right ) + \sqrt{n}
\end{aligned}
\end{equation*}
When we use the Master Theorem on the left inequality, $a=2$, $b=3$ and $f(n) = n^{0.5}$\\
$n^{log_b a} = n^{log_3 2}=n^{0.631}$\\
$f(n) = n^{0.5}=n^{log_b a -\epsilon}=O(n^{log_b a -\epsilon})$ for some $\epsilon > 0$\\
We can use case 1 of the Master Theorem, so\\
$T(n) \geq \Theta(n^{0.631})$\\
When we use the Master Theorem on the right inequality,\\
 $a=2$, $b=2$ and $f(n) = n^{0.5}=\Omega(n^{log_2 2 - \epsilon})=\Omega(n^{1 - \epsilon})$for some $\epsilon > 0$\\
We can use case 1 of the Master Theorem, so\\
$T(n) \leq \Theta(n)$\\
From the above two inequalities for $T(n)$, we can say that
\begin{equation*}
\begin{aligned}
T(n) &= \Theta(n^x) \text{, where } 0.631 \leq x \leq 1\\
\text{So }T(n) &= O(n) \text{ is the tightest upper bound I can find}
\end{aligned}
\end{equation*}
\part 
\end{parts}

\titledquestion{Bubble sort}
Recall the bubble sort algorithm (pseudocode at {\sf http://en.wikipedia.org/wiki/Bubble\_sort}). Recall that the worst case running time is $O(n^2)$.
\begin{parts}
\part[3] Give an example of an input array $A[]$ that is (a) not sorted to begin with, and (b) the algorithm takes time $O(n)$ on $A[]$.
\part[5] Give an example of an input array on which the algorithm takes time $\Theta(n^{3/2})$.
\end{parts}

\titledquestion{Pecking orders}
({\em Source:} Jeff Erickson's exercises)\\
Whenever groups of pigeons gather, they instinctively establish a pecking order. For any pair of pigeons, one pigeon always pecks the other, driving it away from food or potential mates. The same pair of pigeons always chooses the same pecking order, even after years of separation, no matter what other pigeons are around. Surprisingly, the overall pecking order can contain cycles -- for example, pigeon $A$ pecks pigeon $B$, which pecks pigeon $C$, which pecks pigeon $A$. 

\begin{parts}
\part[5] Prove that any finite set of pigeons can be arranged in a row from left to right so that every pigeon pecks the pigeon immediately to its left. [\emph{Hint:} start with two piegons, and consider placing the rest one after another.]
\part[5] Suppose you are given a directed graph representing the pecking relationships among a set of $n$ pigeons. The graph contains one vertex per pigeon, and it contains an edge $i \rightarrow j$ if and only if pigeon $i$ pecks pigeon $j$. Describe and analyze an algorithm to compute a pecking order for the pigeons, as guaranteed by part (a). Your algorithm should run in time polynomial in $n$.
\end{parts}

\titledquestion{More divide, better run time}
{\em Moral:} as long as the ``conquer'' step is not too expensive, dividing a problem into smaller sub-problems typically helps. 

Consider the problem of multiplying two $n$-digit integers.  We saw in class (Lecture 3, Karatsuba's algorithm) that dividing into two $n/2$ bit numbers and combining appropriately, we can compute the product in time $O(n^{1.585..})$. So we can wonder: can division into three pieces help?

Suppose we have two $n$-digit integers $A, B$. Split $A$ into $A_1$,  $A_2$ and $A_3$, each having $n/3$ digits (assume $n$ is a power of $3$ for this problem). So also, split $B$ into $B_1, B_2$ and $B_3$. If the numbers are in base 10, we can write $A = 10^{2n/3} A_1 + 10^{n/3} A_2 + A_3$.  Let $p(z)$ be the polynomial $A_1 z^2 + A_2 z + A_3$, and let $q(z) = B_1 z^2 + B_2 z + B_3$.  Define $r(z) = p(z) q(z)$.  The degree of $r(z)$ is $4$, so $r(z) = C_1 z^4 + C_2 z^3 + C_3 z^2 + C_4 z + C_5$, for some coefficients $C_i$.  

\begin{parts}
\part[2] Observe that the product of $A$ and $B$ is $r(10^{n/3})$.
\part[2] Observe that once we know the $C_i$, assuming they are $O(n)$ digits each, $r(10^{n/3})$ can be found in $O(n)$ time.
\part[4] We thus need to find the $C_i$. The trick is to find the values of $r(z)$ at a few {\em small} values of $z$. Specifically, we find $r(z)$ for $z \in \{-2, -1, 0, 1, 2\}$. Show that we can compute each of these $r(z)$ in time $T(n/3) + O(n)$, where $T(n/3)$ is the time needed to multiply two $n/3$ digit numbers.  Explain why these values uniquely determine $C_i$.  [{\em Hint:} use $ r = p \cdot q$, and the degree of $r$.]
\part[4] To find the $C_i$, write a system of linear equations, and show how these can be solved to obtain $C_i$ in $O(n)$ time.

These observations let us conclude that $T(n) = 5 T(n/3) + O(n)$, which results in an overall run time of $O(n^{1.464..})$, which is better than Karatsuba's algorithm. (This can be pushed further, to obtain $n^{1+\epsilon}$, for any constant $\epsilon >0$.)
\end{parts}


\end{questions}

\begin{thebibliography}{9}

\bibitem{CLRS} Cormen, T. H., Leiserson, C. E., Rivest, R. L., \& Stein, C. (n.d.).\textit{Introduction to algorithms.}

\end{thebibliography}

\end{document}
